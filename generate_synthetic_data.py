"""
ì‹¤ì œ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¸íŠœë‹ìš© í•©ì„± ëŒ€í™” ë°ì´í„° ìƒì„±
5ê°œ ê°œë… Ã— 3ê°œ ìˆ˜ì¤€ Ã— 3ê°œ ì‹œë‚˜ë¦¬ì˜¤ = 45ê°œ ëŒ€í™”
"""
import json
import logging
from services.llm_service import LLMService

def generate_synthetic_training_data():
    """ì‹¤ì œ DB íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ì„± í›ˆë ¨ ë°ì´í„° ìƒì„±"""

    # ì‹¤ì œ íŒ¨í„´ ë¡œë“œ
    with open("real_patterns.json", "r", encoding="utf-8") as f:
        patterns = json.load(f)

    print("ğŸ“Š ì‹¤ì œ DB íŒ¨í„´ ì •ë³´:")
    print(f"  ë°ì´í„° ì¶œì²˜: {patterns['extraction_summary']['data_source']}")
    print(f"  í›ˆë ¨ìš© ê°œë…: {patterns['extraction_summary']['top_concepts_for_training']}ê°œ")

    llm_service = LLMService()
    training_data = []

    # 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ í…œí”Œë¦¿
    scenarios = [
        {
            "type": "hint_request",
            "student_messages": [
                "ì´ ë¬¸ì œ ì–´ë–»ê²Œ í’€ì–´ì•¼ í•´ìš”?",
                "íŒíŠ¸ ì¢€ ì£¼ì„¸ìš”",
                "ëª¨ë¥´ê² ì–´ìš” ë„ì›€ì´ í•„ìš”í•´ìš”",
                "ì–´ë””ì„œë¶€í„° ì‹œì‘í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”"
            ]
        },
        {
            "type": "similar_problem",
            "student_messages": [
                "ë¹„ìŠ·í•œ ë¬¸ì œ ë” ì£¼ì„¸ìš”",
                "ì—°ìŠµ ë¬¸ì œ ìˆë‚˜ìš”?",
                "ì´ëŸ° ìœ í˜• ë” í’€ì–´ë³´ê³  ì‹¶ì–´ìš”",
                "ë‹¤ë¥¸ ë¬¸ì œë¡œ ì—°ìŠµí• ë˜ìš”"
            ]
        },
        {
            "type": "concept_confusion",
            "student_messages": [
                "ì´ ê°œë…ì´ í—·ê°ˆë ¤ìš”",
                "ì™œ ì´ë ‡ê²Œ ë˜ëŠ”ì§€ ëª¨ë¥´ê² ì–´ìš”",
                "ê³µì‹ì„ ì–´ë–»ê²Œ ì ìš©í•´ì•¼ í•˜ë‚˜ìš”?",
                "ì´í•´ê°€ ì•ˆ ë˜ëŠ” ë¶€ë¶„ì´ ìˆì–´ìš”"
            ]
        }
    ]

    print("\nğŸ¤– ì‹¤ì œ íŒ¨í„´ ê¸°ë°˜ í•©ì„± ëŒ€í™” ë°ì´í„° ìƒì„± ì‹œì‘...")

    for concept in patterns["concepts"]:
        concept_name = concept["concept_name"]
        base_success_rate = concept["success_rate"]
        avg_personal_accuracy = concept["avg_personal_accuracy"]
        avg_global_accuracy = concept["avg_global_accuracy"]

        print(f"\nğŸ“š {concept_name}")
        print(f"  ì‹¤ì œ ì„±ê³µë¥ : {base_success_rate*100:.1f}%")
        print(f"  ê°œì¸ í‰ê·  ì •í™•ë„: {avg_personal_accuracy*100:.1f}%")
        print(f"  ì „ì²´ í‰ê·  ì •í™•ë„: {avg_global_accuracy*100:.1f}%")

        # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ 3ê°€ì§€ ìˆ˜ì¤€ ì„¤ì •
        accuracy_levels = [
            {
                "level": "low",
                "accuracy": max(0.2, avg_personal_accuracy - 0.3),  # ì‹¤ì œë³´ë‹¤ ë‚®ìŒ
                "description": f"ì–´ë ¤ì›€ì„ ëŠë¼ëŠ” ìˆ˜ì¤€ (ì‹¤ì œ í‰ê· : {avg_personal_accuracy*100:.1f}%)"
            },
            {
                "level": "medium",
                "accuracy": avg_personal_accuracy,  # ì‹¤ì œ í‰ê·  ì‚¬ìš©
                "description": f"í‰ê·  ìˆ˜ì¤€ (ì‹¤ì œ ë°ì´í„°)"
            },
            {
                "level": "high",
                "accuracy": min(0.9, avg_personal_accuracy + 0.2),  # ì‹¤ì œë³´ë‹¤ ë†’ìŒ
                "description": f"ìš°ìˆ˜ ìˆ˜ì¤€ (ì‹¤ì œ í‰ê· : {avg_personal_accuracy*100:.1f}%)"
            }
        ]

        for accuracy_level in accuracy_levels:
            for scenario in scenarios:
                # í•™ìƒ ë©”ì‹œì§€ ì„ íƒ
                import random
                student_message = random.choice(scenario["student_messages"])

                # ì‹¤ì œ ë°ì´í„°ë¥¼ í¬í•¨í•œ ë§ì¶¤í˜• íŠœí„° ì‘ë‹µ ìƒì„±
                tutor_response = generate_tutor_response_with_real_data(
                    llm_service, concept_name, accuracy_level, scenario, student_message,
                    base_success_rate, avg_global_accuracy
                )

                # Fine-tuning í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                training_example = {
                    "messages": [
                        {
                            "role": "system",
                            "content": f"ë„ˆëŠ” '{concept_name}' ê°œë…ì— ëŒ€í•´ {accuracy_level['accuracy']*100:.1f}% ì •ë‹µë¥ ì„ ê°€ì§„ í•™ìƒì—ê²Œ ê°œì¸í™”ëœ ìˆ˜í•™ íŠœí„°ë§ì„ ì œê³µí•˜ëŠ” AIì•¼. ì‹¤ì œ ë°ì´í„°: ì´ ê°œë…ì˜ ì „ì²´ í‰ê·  ì„±ê³µë¥ ì€ {base_success_rate*100:.1f}%ì´ê³ , ì „ì²´ í•™ìƒ í‰ê·  ì •í™•ë„ëŠ” {avg_global_accuracy*100:.1f}%ì•¼. í•™ìƒì˜ ìˆ˜ì¤€ì— ë§ëŠ” ì†Œí¬ë¼í‹± ë°©ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•´."
                        },
                        {
                            "role": "user",
                            "content": student_message
                        },
                        {
                            "role": "assistant",
                            "content": tutor_response
                        }
                    ]
                }

                training_data.append(training_example)
                print(f"  âœ… {len(training_data)}/45 - {accuracy_level['level']} Ã— {scenario['type']}")

    # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
    with open("synthetic_training_data.jsonl", "w", encoding="utf-8") as f:
        for example in training_data:
            f.write(json.dumps(example, ensure_ascii=False) + "\n")

    print(f"\nğŸ‰ ì‹¤ì œ íŒ¨í„´ ê¸°ë°˜ í•©ì„± í›ˆë ¨ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(training_data)}ê°œ")
    print("ğŸ“ íŒŒì¼: synthetic_training_data.jsonl")
    print("âœ¨ íŠ¹ì§•: ì‹¤ì œ DB ì„±ê³µë¥ ê³¼ ì •í™•ë„ ë°ì´í„° ë°˜ì˜ë¨")

    return training_data

def generate_tutor_response_with_real_data(llm_service, concept_name, accuracy_level, scenario, student_message, base_success_rate, avg_global_accuracy):
    """ì‹¤ì œ DB ë°ì´í„°ë¥¼ í¬í•¨í•œ GPT ë§ì¶¤í˜• íŠœí„° ì‘ë‹µ ìƒì„±"""

    # ìˆ˜ì¤€ë³„ ë§ì¶¤ ì§€ì¹¨
    level_guidance = {
        "low": "ë§¤ìš° ê¸°ì´ˆì ì´ê³  ë‹¨ê³„ë³„ë¡œ ì²œì²œíˆ ì•ˆë‚´í•˜ì„¸ìš”. ê¸°ë³¸ ê°œë…ë¶€í„° í™•ì¸í•˜ê³  ìì‹ ê°ì„ ë†’ì—¬ì£¼ì„¸ìš”.",
        "medium": "ì ì ˆí•œ ìˆ˜ì¤€ì˜ íŒíŠ¸ë¥¼ ì œê³µí•˜ë˜ ìŠ¤ìŠ¤ë¡œ ìƒê°í•  ì—¬ì§€ë¥¼ ë‚¨ê²¨ì£¼ì„¸ìš”.",
        "high": "ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ íŒíŠ¸ë¡œ ììœ¨ì  ì‚¬ê³ ë¥¼ ìœ ë„í•˜ì„¸ìš”."
    }

    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‘ë‹µ ë°©í–¥
    scenario_guidance = {
        "hint_request": "ì§ì ‘ì ì¸ ë‹µì´ ì•„ë‹Œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìƒê°í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ í˜•íƒœë¡œ íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.",
        "similar_problem": "ë¹„ìŠ·í•œ ìˆ˜ì¤€ì˜ ì—°ìŠµ ë¬¸ì œë¥¼ ì œì‹œí•˜ê±°ë‚˜ ì—°ìŠµ ë°©í–¥ì„ ì œì•ˆí•˜ì„¸ìš”.",
        "concept_confusion": "ê°œë…ì„ ì‰½ê²Œ ì„¤ëª…í•˜ê³  ì´í•´ë¥¼ ë•ëŠ” ì§ˆë¬¸ì„ ì œì‹œí•˜ì„¸ìš”."
    }

    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê°œì¸í™” ì •ë³´
    if accuracy_level["accuracy"] < avg_global_accuracy:
        performance_context = "ì „ì²´ í‰ê· ë³´ë‹¤ ì–´ë ¤ì›€ì„ ëŠë¼ëŠ” í•™ìƒ"
    elif accuracy_level["accuracy"] > avg_global_accuracy:
        performance_context = "ì „ì²´ í‰ê· ë³´ë‹¤ ìš°ìˆ˜í•œ í•™ìƒ"
    else:
        performance_context = "ì „ì²´ í‰ê·  ìˆ˜ì¤€ì˜ í•™ìƒ"

    system_prompt = f"""ë„ˆëŠ” ì‹¤ì œ í•™ìŠµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸í™”ëœ ìˆ˜í•™ íŠœí„°ë§ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ AIì•¼.

ì‹¤ì œ ë°ì´í„° ì •ë³´:
- ê°œë…: {concept_name}
- ì´ í•™ìƒ ì •ë‹µë¥ : {accuracy_level['accuracy']*100:.1f}%
- ì´ ê°œë…ì˜ ì „ì²´ í‰ê·  ì„±ê³µë¥ : {base_success_rate*100:.1f}%
- ì „ì²´ í•™ìƒ í‰ê·  ì •í™•ë„: {avg_global_accuracy*100:.1f}%
- í•™ìƒ íŠ¹ì„±: {performance_context}
- ìš”ì²­ ìœ í˜•: {scenario['type']}

ê°œì¸í™” ì§€ì¹¨:
- ìˆ˜ì¤€ë³„ ì ‘ê·¼: {level_guidance[accuracy_level['level']]}
- ì‘ë‹µ ë°©í–¥: {scenario_guidance[scenario['type']]}

ë°˜ë“œì‹œ ì†Œí¬ë¼í‹± ë°©ì‹ìœ¼ë¡œ í•™ìƒì´ ìŠ¤ìŠ¤ë¡œ ìƒê°í•  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸ í˜•íƒœë¡œ ì‘ë‹µí•˜ê³ , ì‹¤ì œ ë°ì´í„°ë¥¼ ë°˜ì˜í•œ ê°œì¸í™”ëœ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."""

    user_prompt = f"í•™ìƒ ë©”ì‹œì§€: '{student_message}'\n\nìœ„ ì‹¤ì œ ë°ì´í„°ì™€ ìƒí™©ì— ë§ëŠ” ê°œì¸í™”ëœ íŠœí„° ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”."

    try:
        response = llm_service.call_llm(system_prompt, user_prompt, [])
        return response
    except Exception as e:
        logging.error(f"ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ íŠœí„° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        # ë°±ì—… ì‘ë‹µ
        return f"{concept_name}ì— ëŒ€í•´ ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ì–´ë µê²Œ ëŠê»´ì§€ë‚˜ìš”? í˜„ì¬ {accuracy_level['accuracy']*100:.1f}% ìˆ˜ì¤€ì´ë‹ˆê¹Œ ì°¨ê·¼ì°¨ê·¼ ì ‘ê·¼í•´ë³´ì!"

def generate_tutor_response(llm_service, concept_name, accuracy_level, scenario, student_message, base_success_rate):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ (deprecated)"""
    return generate_tutor_response_with_real_data(llm_service, concept_name, accuracy_level, scenario, student_message, base_success_rate, 0.5)

if __name__ == "__main__":
    generate_synthetic_training_data()