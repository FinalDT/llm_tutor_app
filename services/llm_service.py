import json
import logging
from typing import List, Dict, Any, Optional
from openai import AzureOpenAI
from config.settings import settings


class LLMService:
    """OpenAI LLM ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self):
        self.client = AzureOpenAI(
            api_key=settings.openai_api_key,
            azure_endpoint=settings.openai_endpoint,
            api_version=settings.openai_api_version
        )

    def generate_session_summary_prompt(self, total_questions: int, correct_count: int,
                                      wrong_question_numbers: List[str], weakest_concepts: List[str]) -> Dict[str, str]:
        """ì„¸ì…˜ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        system_prompt = "ë„ˆëŠ” í•™ìƒì˜ ì§„ë‹¨ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì •í™•í•œ ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ìš”ì•½í•˜ê³  ì „ë‹¬í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼."

        user_prompt = f"""
        ### [ë°°ê²½ ë°ì´í„°]
        - ì „ì²´ ë¬¸í•­ ìˆ˜: {total_questions}
        - ë§ì¶˜ ë¬¸í•­ ìˆ˜: {correct_count}
        - í‹€ë¦° ë¬¸ì œ ë²ˆí˜¸ ëª©ë¡: {', '.join(wrong_question_numbers)}
        - ë³´ì¶©ì´ í•„ìš”í•œ ê°œë… ëª©ë¡: {', '.join(weakest_concepts)}

        ### [ë„ˆì˜ ì„ë¬´]
        ìœ„ [ë°°ê²½ ë°ì´í„°]ë¥¼ ê·¸ëŒ€ë¡œ ì½ì–´ì„œ [ì¶œë ¥ í˜•ì‹]ì— ë§ì¶° ë¬¸ì¥ì„ ì™„ì„±í•´. ì ˆëŒ€ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ë§ì„ ì¶”ê°€í•˜ë©´ ì•ˆ ë¼.

        ### [ì¶œë ¥ í˜•ì‹]
        ì§„ë‹¨ í…ŒìŠ¤íŠ¸ í‘¸ëŠë¼ ìˆ˜ê³  ë§ì•˜ì–´! ê²°ê³¼ë¥¼ ì•Œë ¤ì¤„ê²Œ.\\n\\nì „ì²´ [ì „ì²´ ë¬¸í•­ ìˆ˜] ë¬¸ì œ ì¤‘ì—ì„œ [ë§ì¶˜ ë¬¸í•­ ìˆ˜] ë¬¸ì œë¥¼ ë§í˜”ë„¤. ì •ë§ ì˜í–ˆì–´! ğŸ‘\\n\\nì´ë²ˆ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì•„ì‰½ê²Œë„ [í‹€ë¦° ë¬¸ì œ ë²ˆí˜¸ ëª©ë¡] ë²ˆ ë¬¸ì œë¥¼ í‹€ë ¸ë”ë¼. ë°ì´í„°ë¥¼ ë¶„ì„í•´ë³´ë‹ˆ, ì£¼ë¡œ "[ë³´ì¶©ì´ í•„ìš”í•œ ê°œë… ëª©ë¡]" ê°œë…ë“¤ì´ ì¡°ê¸ˆ í—·ê°ˆë¦¬ëŠ” ê²ƒ ê°™ì•„.\\n\\nìš°ë¦¬ ê°™ì´ "[ë³´ì¶©ì´ í•„ìš”í•œ ê°œë… ëª©ë¡ ì¤‘ ì²« ë²ˆì§¸ ê°œë…]"ì— ëŒ€í•œ í•™ìŠµì„ ì‹œì‘í•´ë³¼ê¹Œ?
        """

        return {"system": system_prompt, "user": user_prompt}

    def generate_hint_prompt(self, concept_name: str, student_message: str) -> Dict[str, str]:
        """íŒíŠ¸ ìš”ì²­ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        system_prompt = "ë„ˆëŠ” ì •ë‹µì„ ì•Œë ¤ì£¼ì§€ ì•Šê³  ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìƒê°í•˜ê²Œ ë§Œë“œëŠ” 'ì†Œí¬ë¼í‹± ë°©ì‹'ì˜ íŒíŠ¸ë¥¼ ì œê³µí•˜ëŠ” AI íŠœí„°ì•¼."

        user_prompt = f"""### ë°°ê²½ ì •ë³´
- ê´€ë ¨ ê°œë…: {concept_name}
- í•™ìƒ ë©”ì‹œì§€: "{student_message}"

### ì„ë¬´
ì ˆëŒ€ í•™ìŠµ ì „ëµì´ë‚˜ ê¸´ ê²©ë ¤ ë©”ì‹œì§€ë¥¼ ë§í•˜ì§€ ë§ê³ , ì˜¤ì§ ë¬¸ì œ í’€ì´ì— ë„ì›€ì´ ë˜ëŠ” ë‹¤ìŒ ë‹¨ê³„ ì§ˆë¬¸ì„ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´."""

        return {"system": system_prompt, "user": user_prompt}

    def generate_similar_item_prompt(self, concept_name: str, tag_accuracy: float) -> Dict[str, str]:
        """ìœ ì‚¬ ë¬¸í•­ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        system_prompt = "ë„ˆëŠ” í•™ìƒì˜ ìˆ˜ì¤€ì— ë§ëŠ” ìƒˆë¡œìš´ ìˆ˜í•™ ì—°ìŠµ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” AIì•¼. ë°˜ë“œì‹œ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•´."

        user_prompt = f"""### ì •ë³´
- ê°œë…: '{concept_name}'
- í•™ìƒì˜ ì´ ê°œë… ì •í™•ë„: {tag_accuracy * 100:.1f}%

### ì„ë¬´
'{concept_name}' ê°œë…ì— ëŒ€í•œ ìƒˆë¡œìš´ ìœ ì‚¬ ë¬¸í•­ì„ ìƒì„±í•´. í•™ìƒì˜ ì •í™•ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ë„ˆë¬´ ì–´ë µì§€ ì•Šê²Œ ë§Œë“¤ì–´ì•¼ í•´.

### ì¤‘ìš”í•œ ì£¼ì˜ì‚¬í•­
1. ë°˜ë“œì‹œ í•´ì„¤ì˜ ê³„ì‚° ê³¼ì •ì„ ë¨¼ì € ì™„ë£Œí•œ í›„, ê·¸ ê²°ê³¼ë¥¼ correct_answerì— ì…ë ¥í•´ì•¼ í•´
2. correct_answerì™€ explanationì˜ ìµœì¢… ë‹µì´ ì¼ì¹˜í•´ì•¼ í•´
3. ê³„ì‚° ì‹¤ìˆ˜ê°€ ì—†ë„ë¡ ë‹¨ê³„ë³„ë¡œ ê²€ì¦í•´ì¤˜

### ì¶œë ¥ í˜•ì‹ (JSON)
{{"new_question_text": "...", "correct_answer": "...", "explanation": "..."}}

### ì˜ˆì‹œ ê²€ì¦ ê³¼ì •
ë¬¸ì œë¥¼ ë§Œë“  í›„ ë°˜ë“œì‹œ:
1. explanationì—ì„œ ë‹¨ê³„ë³„ ê³„ì‚° ìˆ˜í–‰
2. ìµœì¢… ê²°ê³¼ ê°’ í™•ì¸
3. correct_answerì— ë™ì¼í•œ ê°’ ì…ë ¥
4. ë‘ ê°’ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ì¬í™•ì¸"""

        return {"system": system_prompt, "user": user_prompt}

    def generate_feedback_prompt(self, concept_name: str, tag_accuracy: float) -> Dict[str, str]:
        """ì¼ë°˜ í”¼ë“œë°± í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        system_prompt = "ë„ˆëŠ” í•™ìƒì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ê°œì¸í™”ëœ í•™ìŠµ ì „ëµê³¼ ê²©ë ¤ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ AI í•™ìŠµ ì½”ì¹˜ì•¼."

        user_prompt = f"""### í•™ìƒ í•™ìŠµ ë°ì´í„°
- ê´€ë ¨ ê°œë…: {concept_name}
- ì´ í•™ìƒì˜ í•´ë‹¹ ê°œë… ì •í™•ë„: {tag_accuracy * 100:.1f}%

### ë„ˆì˜ ì„ë¬´
ìœ„ ë°ì´í„°ë¥¼ 'í•´ì„'í•´ì„œ, í•™ìƒì—ê²Œ ê²©ë ¤ ë©”ì‹œì§€ì™€ êµ¬ì²´ì ì¸ í•™ìŠµ ì „ëµì„ ìš”ì•½í•´ì¤˜."""

        return {"system": system_prompt, "user": user_prompt}

    def generate_generated_item_hint_prompt(self, question_text: str, student_message: str) -> Dict[str, str]:
        """ìƒì„±ëœ ë¬¸í•­ íŒíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê¸°ì¡´ ë²„ì „ - í˜¸í™˜ì„± ìœ ì§€)"""
        system_prompt = "ë„ˆëŠ” í•™ìƒì´ ë³´ê³  ìˆëŠ” ë¬¸ì œì— ëŒ€í•´, ì •ë‹µì„ ì•Œë ¤ì£¼ì§€ ì•Šê³  ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìƒê°í•˜ê²Œ ë§Œë“œëŠ” 'ì†Œí¬ë¼í‹± ë°©ì‹'ì˜ íŒíŠ¸ë¥¼ ì œê³µí•˜ëŠ” AI íŠœí„°ì•¼."

        user_prompt = f"""### ë¬¸ì œ í…ìŠ¤íŠ¸
{question_text}

### í•™ìƒ ë©”ì‹œì§€
"{student_message}"

### ì„ë¬´
ìœ„ ë¬¸ì œì— ëŒ€í•œ ê°„ê²°í•œ íŒíŠ¸ë¥¼ ì§ˆë¬¸ í˜•íƒœë¡œ ì œê³µí•´ì¤˜."""

        return {"system": system_prompt, "user": user_prompt}

    def generate_personalized_hint_prompt(self, question_text: str, student_message: str,
                                        personalization_data: Dict[str, Any]) -> Dict[str, str]:
        """ê°œì¸í™”ëœ íŒíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        learner_id = personalization_data.get("learner_id", "Unknown")
        original_concept = personalization_data.get("original_concept", "Unknown")
        personal_accuracy = personalization_data.get("personal_accuracy")
        hint_level = personalization_data.get("hint_level", "beginner")

        system_prompt = f"""ë„ˆëŠ” í•™ìƒì˜ ê°œì¸ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ì†Œí¬ë¼í‹± íŒíŠ¸ë¥¼ ì œê³µí•˜ëŠ” AI íŠœí„°ì•¼.

### í•™ìŠµì ì •ë³´
- í•™ìŠµì ID: {learner_id}
- ê´€ë ¨ ê°œë…: {original_concept}
- ê°œì¸ ì •í™•ë„: {f"{personal_accuracy*100:.1f}%" if personal_accuracy else "ì •ë³´ ì—†ìŒ"}
- íŒíŠ¸ ë ˆë²¨: {hint_level}

### íŒíŠ¸ ì œê³µ ì›ì¹™
- {hint_level} í•™ìŠµìì—ê²Œ ì í•©í•œ ìˆ˜ì¤€ìœ¼ë¡œ ì¡°ì ˆ
- ì ˆëŒ€ ì •ë‹µì„ ì§ì ‘ ì•Œë ¤ì£¼ì§€ ë§ê³  ì†Œí¬ë¼í‹± ì§ˆë¬¸ìœ¼ë¡œ ìœ ë„
- í•™ìŠµìì˜ ì´í•´ë„ì— ë§ëŠ” ë‹¨ê³„ë³„ ì ‘ê·¼"""

        # íŒíŠ¸ ë ˆë²¨ë³„ ìƒì„¸ ì§€ì¹¨
        level_instructions = {
            "beginner": "ë§¤ìš° êµ¬ì²´ì ì´ê³  ë‹¨ê³„ë³„ë¡œ ì²œì²œíˆ ì•ˆë‚´. ê¸°ë³¸ ê°œë…ë¶€í„° í™•ì¸",
            "intermediate": "ì¤‘ê°„ ìˆ˜ì¤€ì˜ íŒíŠ¸. í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ì œì‹œí•˜ë˜ ìŠ¤ìŠ¤ë¡œ ìƒê°í•  ì—¬ì§€ ì œê³µ",
            "advanced": "ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ íŒíŠ¸. ìµœì†Œí•œì˜ ê°€ì´ë“œë¡œ ììœ¨ì  ì‚¬ê³  ìœ ë„"
        }

        user_prompt = f"""### ë¬¸ì œ í…ìŠ¤íŠ¸
{question_text}

### í•™ìƒ ë©”ì‹œì§€
"{student_message}"

### ê°œì¸í™” ì§€ì¹¨
{level_instructions.get(hint_level, level_instructions["beginner"])}

### ì„ë¬´
ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì´ í•™ìŠµìì—ê²Œ ê°€ì¥ ì í•©í•œ ì†Œí¬ë¼í‹± íŒíŠ¸ë¥¼ ì œê³µí•´ì¤˜."""

        return {"system": system_prompt, "user": user_prompt}

    def generate_guided_hint_prompt(self, question_text: str, student_message: str,
                                   answer_analysis: Dict[str, Any], personalization_data: Dict[str, Any]) -> Dict[str, str]:
        """ë¶€ë¶„ ì •ë‹µì´ë‚˜ ì¢‹ì€ ì ‘ê·¼ì— ëŒ€í•œ ê°€ì´ë“œ íŒíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        confidence = answer_analysis.get("confidence", 0.0)
        is_partial_correct = answer_analysis.get("is_partial_correct", False)
        has_good_approach = answer_analysis.get("has_good_approach", False)
        hint_level = personalization_data.get("hint_level", "beginner")

        system_prompt = f"""ë„ˆëŠ” í•™ìƒì˜ ë¶€ë¶„ ì •ë‹µì´ë‚˜ ì¢‹ì€ ì ‘ê·¼ ë°©ë²•ì„ ì¸ì •í•˜ê³  ê²©ë ¤í•˜ë©°, ì™„ì „í•œ ì •ë‹µìœ¼ë¡œ ì´ë„ëŠ” AI íŠœí„°ì•¼.

### í•™ìƒ ìƒí™© ë¶„ì„
- ë‹µì•ˆ ì‹ ë¢°ë„: {confidence*100:.1f}%
- ë¶€ë¶„ ì •ë‹µ ì—¬ë¶€: {'ì˜ˆ' if is_partial_correct else 'ì•„ë‹ˆì˜¤'}
- ì ‘ê·¼ ë°©ë²• ì ì ˆì„±: {'ì¢‹ìŒ' if has_good_approach else 'ë³´í†µ'}
- íŒíŠ¸ ë ˆë²¨: {hint_level}

### ê°€ì´ë“œ ì›ì¹™
1. ë¨¼ì € í•™ìƒì˜ ì‹œë„ë¥¼ ì¸ì •í•˜ê³  ê²©ë ¤
2. ë¶€ì¡±í•œ ë¶€ë¶„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì 
3. ë‹¤ìŒ ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„
4. ì •ë‹µì— ê°€ê¹Œì›Œì§€ë„ë¡ ë°©í–¥ ì œì‹œ"""

        if is_partial_correct:
            focus = "ìˆ«ìëŠ” ì •í™•í•˜ì§€ë§Œ ë‹¨ìœ„ë‚˜ í‘œê¸°ë²•ì„ ì™„ì„±í•˜ë„ë¡ ë„ì›€"
        elif has_good_approach:
            focus = "ì ‘ê·¼ ë°©ë²•ì´ ì¢‹ìœ¼ë‹ˆ ê³„ì‚° ê³¼ì •ì„ ë” ì •í™•í•˜ê²Œ ì§„í–‰í•˜ë„ë¡ ë„ì›€"
        else:
            focus = "í˜„ì¬ ì‹œë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ ì•ˆë‚´"

        user_prompt = f"""### ë¬¸ì œ
{question_text}

### í•™ìƒ ë‹µì•ˆ
"{student_message}"

### ê°€ì´ë“œ ë°©í–¥
{focus}

### ì„ë¬´
í•™ìƒì˜ ì‹œë„ë¥¼ ê²©ë ¤í•˜ê³ , ì •ë‹µì— ë” ê°€ê¹Œì›Œì§ˆ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì†Œí¬ë¼í‹± ì§ˆë¬¸ìœ¼ë¡œ ì œì‹œí•´ì¤˜."""

        return {"system": system_prompt, "user": user_prompt}

    def analyze_user_intent(self, user_message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        current_stage = context.get("current_stage", "unknown")
        has_current_problem = context.get("has_current_problem", False)

        system_prompt = """ë„ˆëŠ” í•™ìŠµìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•´ì„œ ì •í™•í•œ ì˜ë„ë¥¼ íŒŒì•…í•˜ëŠ” AIì•¼.
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•´."""

        user_prompt = f"""### ìƒí™© ì •ë³´
- í˜„ì¬ ë‹¨ê³„: {current_stage}
- ë¬¸ì œ í’€ì´ ì¤‘: {'ì˜ˆ' if has_current_problem else 'ì•„ë‹ˆì˜¤'}

### ì‚¬ìš©ì ë©”ì‹œì§€
"{user_message}"

### ì˜ë„ ë¶„ë¥˜ ê¸°ì¤€
1. answer_attempt: ìˆ«ìë‚˜ êµ¬ì²´ì  ë‹µì„ ì œì‹œ (ì˜ˆ: "210", "210cmÂ²", "ë‹µì€ 5ì•¼")
2. hint_request: íŒíŠ¸ë‚˜ ë„ì›€ ìš”ì²­ (ì˜ˆ: "íŒíŠ¸ ì£¼ì„¸ìš”", "ì–´ë–»ê²Œ í’€ì–´ìš”?", "ëª¨ë¥´ê² ì–´ìš”")
3. answer_request: ì •ë‹µì„ ì§ì ‘ ì•Œë ¤ë‹¬ë¼ëŠ” ìš”ì²­ (ì˜ˆ: "ì •ë‹µ ì•Œë ¤ì¤˜", "ë‹µì´ ë­ì•¼?")
4. concept_explanation: ê°œë… ì„¤ëª… ìš”ì²­ (ì˜ˆ: "ì´ ê°œë… ì„¤ëª…í•´ì¤˜", "ì›ë¦¬ê°€ ë­ì•¼?")
5. easier_problem: ë” ì‰¬ìš´ ë¬¸ì œ ìš”ì²­ (ì˜ˆ: "ë„ˆë¬´ ì–´ë ¤ì›Œ", "ì‰¬ìš´ ë¬¸ì œ ì¤˜")
6. harder_problem: ë” ì–´ë ¤ìš´ ë¬¸ì œ ìš”ì²­ (ì˜ˆ: "ë” ì–´ë ¤ìš´ ê²ƒ", "ë„ì „ì ì¸ ë¬¸ì œ")
7. different_problem: ë‹¤ë¥¸ ë¬¸ì œ ìš”ì²­ (ì˜ˆ: "ë‹¤ë¥¸ ë¬¸ì œ", "ìƒˆë¡œìš´ ë¬¸ì œ")
8. different_concept: ë‹¤ë¥¸ ê°œë… í•™ìŠµ (ì˜ˆ: "ë‹¤ë¥¸ ê°œë…", "ì´ê±° ë§ê³  ë‹¤ë¥¸ ê±°")
9. session_control: í•™ìŠµ ì¤‘ë‹¨/ì¢…ë£Œ (ì˜ˆ: "ê·¸ë§Œí• ë˜", "ë‚˜ê°€ê¸°", "ì‰¬ê³  ì‹¶ì–´")
10. clarification: ì„¤ëª…ì´ë‚˜ ì¬ì§ˆë¬¸ (ì˜ˆ: "ë¬´ìŠ¨ ëœ»ì´ì•¼?", "ë‹¤ì‹œ ë§í•´ì¤˜")
11. general_chat: ì¼ë°˜ ëŒ€í™” (ì˜ˆ: "ì•ˆë…•", "ê³ ë§ˆì›Œ", "í™”ì¥ì‹¤ ê°€ì•¼ í•´")

### ì¶œë ¥ í˜•ì‹ (JSON)
{{"intent": "ë¶„ë¥˜ëœ_ì˜ë„", "confidence": 0.0-1.0_ì‹ ë¢°ë„, "reasoning": "íŒë‹¨_ê·¼ê±°"}}"""

        return {"system": system_prompt, "user": user_prompt}

    def call_llm(self, system_prompt: str, user_prompt: str, conversation_history: List[Dict[str, str]],
                 response_format: str = "text") -> str:
        """LLM í˜¸ì¶œ ë° ì‘ë‹µ ë°˜í™˜"""
        try:
            response_format_config = {"type": response_format}

            messages_to_send = [{"role": "system", "content": system_prompt}] + conversation_history
            messages_to_send.append({"role": "user", "content": user_prompt})

            response = self.client.chat.completions.create(
                model=settings.openai_model,
                messages=messages_to_send,
                response_format=response_format_config
            )

            return response.choices[0].message.content

        except Exception as e:
            logging.error(f"LLM call failed: {e}")
            raise

    def parse_similar_item_response(self, response_content: str, concept_name: str) -> Dict[str, Any]:
        """ìœ ì‚¬ ë¬¸í•­ ìƒì„± ì‘ë‹µ íŒŒì‹±"""
        try:
            generated_data = json.loads(response_content)

            # ë‹µì•ˆê³¼ í•´ì„¤ ì¼ì¹˜ì„± ê²€ì¦
            correct_answer = generated_data.get('correct_answer', '')
            explanation = generated_data.get('explanation', '')

            # ì •ë‹µì—ì„œ ìˆ«ì ì¶”ì¶œ
            import re
            answer_numbers = re.findall(r'\d+(?:\.\d+)?', correct_answer)
            explanation_numbers = re.findall(r'\d+(?:\.\d+)?', explanation)

            # ì¼ì¹˜ì„± ê²€ì¦: ì •ë‹µì˜ ìˆ«ìê°€ í•´ì„¤ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if answer_numbers and explanation_numbers:
                if not any(num in explanation_numbers for num in answer_numbers):
                    logging.warning(f"Answer-explanation mismatch detected: answer={correct_answer}, explanation numbers={explanation_numbers}")
                    # í•´ì„¤ì—ì„œ ê°€ì¥ í° ìˆ«ìë¥¼ ì •ë‹µìœ¼ë¡œ ìˆ˜ì • (ì¼ë°˜ì ìœ¼ë¡œ ìµœì¢… ë‹µ)
                    if explanation_numbers:
                        largest_num = max(explanation_numbers, key=float)
                        # ë‹¨ìœ„ ìœ ì§€í•˜ë©´ì„œ ìˆ«ìë§Œ êµì²´
                        original_units = re.findall(r'[a-zA-ZÂ²Â³Â°]+', correct_answer)
                        corrected_answer = largest_num + (original_units[0] if original_units else '')
                        generated_data['correct_answer'] = corrected_answer
                        logging.info(f"Corrected answer from {correct_answer} to {corrected_answer}")

            ai_feedback = f"ì¢‹ì•„! '{concept_name}' ê°œë…ì„ ë” ì—°ìŠµí•´ë³¼ê¹Œ? ì•„ë˜ ë¬¸ì œë¥¼ í’€ì–´ë´.\n\n{generated_data.get('new_question_text')}"

            return {
                "feedback": ai_feedback,
                "generated_question_data": generated_data
            }
        except json.JSONDecodeError as e:
            logging.error(f"Failed to parse similar item response: {e}")
            raise