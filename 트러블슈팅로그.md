# 트러블슈팅 로그

## 2025-09-28: function_app.py 모듈화 리팩토링

### 문제 상황
- **근본적 원인**: function_app.py가 194줄로 비대해져 디버깅과 유지보수가 어려운 상태
- **세부 문제점**:
  1. 단일 책임 원칙 위반 (DB, 비즈니스, LLM 로직 혼재)
  2. 재사용성 부족 (공통 기능 하드코딩)
  3. 테스트 어려움 (독립적 테스트 불가)
  4. 확장성 제약 (새 기능 추가 시 메인 함수 비대화)

### 해결 방안
#### 1단계: 환경변수 관리 분리
- **파일**: `config/settings.py`
- **변경 내용**: 환경변수 로딩 및 검증 로직 중앙화
- **장점**: 설정 변경 시 영향 범위 최소화, 환경변수 검증 자동화

#### 2단계: 데이터베이스 로직 분리
- **파일**: `database/db_service.py`
- **변경 내용**:
  - DB 연결 관리
  - 모든 쿼리 메서드화
  - `format_session_results_for_llm()` 함수 이동
- **장점**: DB 관련 로직 중앙화, 연결 풀링 등 최적화 가능

#### 3단계: LLM 서비스 로직 분리
- **파일**: `services/llm_service.py`
- **변경 내용**:
  - OpenAI 클라이언트 초기화
  - 각 기능별 프롬프트 생성 메서드
  - LLM 호출 및 응답 파싱 로직
- **장점**: LLM 관련 로직 중앙화, 프롬프트 템플릿 관리 용이

#### 4단계: 비즈니스 로직 핸들러 분리
- **파일**: `handlers/session_handler.py`, `handlers/feedback_handler.py`, `handlers/generated_item_handler.py`
- **변경 내용**: 각 request_type별 처리 로직을 독립된 핸들러로 분리
- **장점**: 기능별 독립 개발/테스트, 코드 가독성 향상, 새 기능 추가 시 기존 코드 영향 최소화

#### 5단계: 응답 유틸리티 분리
- **파일**: `utils/response_builder.py`
- **변경 내용**: HTTP 응답 생성 로직 유틸리티화
- **장점**: 응답 포맷 일관성 보장, 에러 처리 표준화

#### 6단계: 메인 함수 최적화
- **파일**: `function_app.py` (리팩토링)
- **변경 내용**: 라우팅과 예외 처리만 담당 (194줄 → 62줄)
- **장점**: 코드 가독성 극대화, 전체 플로우 파악 용이

### 결과
- **Before**: 194줄의 단일 파일
- **After**: 62줄의 메인 파일 + 9개 모듈 파일
- **개선 효과**:
  - 각 모듈별 독립적 테스트 가능
  - 코드 가독성 대폭 향상
  - 새 기능 추가 시 기존 코드 영향 최소화
  - 디버깅 효율성 증대

### 파일 구조
```
llm_tutor_app/
├── function_app.py (62줄)
├── config/
│   └── settings.py
├── database/
│   └── db_service.py
├── services/
│   └── llm_service.py
├── handlers/
│   ├── session_handler.py
│   ├── feedback_handler.py
│   └── generated_item_handler.py
└── utils/
    └── response_builder.py
```

### 검증 상태
- ✅ 모든 모듈 파일 생성 완료
- ✅ function_app.py 리팩토링 완료
- ✅ API 인터페이스 동일하게 유지
- ⚠️ 실제 동작 테스트 필요 (환경 설정 후)

### 주의사항
- 모듈 간 의존성이 올바르게 설정되었는지 실제 실행 시 확인 필요
- 환경변수명이 기존과 동일한지 검증 필요
- Azure Functions 배포 시 새로운 모듈들이 포함되는지 확인 필요

---

## 2025-09-28: 실제 사용환경 대화형 힌트 시스템 구축 및 API 오류 해결

### 문제 상황
- **근본적 원인**: `generated_item` 타입 요청에서 400 오류 발생
- **세부 문제점**:
  1. API 400 오류: "Required fields are missing: request_type, learnerID"
  2. 하드코딩된 테스트 시나리오로 인한 실제 사용환경과의 차이
  3. AI 중심 설계 부족 (모든 학생 답변이 미리 정해짐)

### 해결 방안
#### 1단계: API 오류 해결
- **파일**: `function_app.py`
- **변경 내용**: `generated_item` 타입에 대해 `learnerID` 필수 검증 제외
- **장점**: API 요청 구조 개선, 오류 해결

#### 2단계: 실제 사용환경 테스트 시스템 구축
- **파일**: `test_real_interactive_hint.py`
- **변경 내용**: 
  - 사용자가 직접 답변 입력하는 대화형 테스트
  - AI가 실시간으로 학생 답변 분석 및 다음 소크라틱 질문 생성
  - 두 가지 테스트 모드 (실제 대화 / 데모 시나리오)
- **장점**: 실제 서비스 환경과 동일한 테스트 경험

#### 3단계: AI 연결 상태 검증
- **파일**: `test_ai_connection.py`
- **변경 내용**: AI 연결 상태 및 응답 품질 자동 검증
- **장점**: 소크라틱 질문 형태, 정답 직접 공개 방지 등 자동 확인

#### 4단계: 하드코딩 제거
- **변경 내용**: 모든 학생 답변을 사용자 직접 입력으로 변경
- **장점**: AI가 학생 답변을 실시간 분석하여 동적 대화 흐름 생성

### 결과
- **API 오류**: 400 오류 → 200 성공 응답
- **AI 응답 품질**: 완벽한 소크라틱 질문 형태 확인
- **응답 시간**: 평균 2-7초로 빠른 응답
- **연결 안정성**: 여러 번 연속 요청 모두 성공

### 파일 구조 업데이트
```
llm_tutor_app/
├── test_real_interactive_hint.py  # 실제 사용환경 대화형 힌트 테스트
├── test_ai_connection.py          # AI 연결 상태 테스트
└── debug_api.py                   # API 디버깅 도구
```

### 검증 상태
- ✅ API 400 오류 해결 완료
- ✅ AI 연결 상태 검증 완료
- ✅ 소크라틱 질문 형태 검증 완료
- ✅ 실제 사용환경 테스트 시스템 구축 완료
- ⚠️ 실제 사용자 테스트 필요

### 예방책
- API 요청 타입별 필수 필드 검증 로직 개선
- 실제 사용환경과 동일한 테스트 시나리오 우선 구성
- AI 응답 품질 자동 검증 시스템 구축